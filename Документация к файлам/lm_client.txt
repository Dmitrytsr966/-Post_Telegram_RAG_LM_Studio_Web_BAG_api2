### Документация для `lm_client.py`

#### **Обзор**
Модуль `lm_client.py` содержит класс `FreeGPT4Client` для взаимодействия с LLM через OpenAI-совместимый API. Класс предназначен для генерации текстового контента с учетом ограничений Telegram (4096 символов), интеграции с RAG-системой, валидации контента и обработки ошибок. Используется репозиторий [Free-GPT4-WEB-API](https://github.com/Simatwa/Free-GPT4-WEB-API) через Docker.

---

#### **Ключевые особенности**
1. **Динамическое управление контекстом**  
   Автоматическое сокращение истории диалога и контекста RAG для соблюдения лимита `LM_MAX_TOTAL_CHARS` (10 000 символов).
2. **Валидация контента**  
   Интеграция с `ContentValidator` для очистки ответов LLM (удаление тегов `<think>`, некорректных данных).
3. **Логирование**  
   Сохранение промптов, успешных/неудачных ответов в директориях `logs/freegpt4/`.
4. **Механизм повторов**  
   Автоматические повторы при ошибках API с адаптацией контекста.
5. **Соблюдение Telegram-лимитов**  
   Автоматическое сокращение текста до 4096 символов.

---

#### **Класс `FreeGPT4Client`**

##### **Конструктор**
```python
def __init__(self, url: str, model: str, config: Dict[str, Any])
```
**Параметры:**
- `url`: URL OpenAI-совместимого API (например, `http://localhost:1337/v1/chat/completions`).
- `model`: Имя модели (например, `gpt-4`).
- `config`: Конфигурационный словарь с ключами:
  - `max_tokens` (int, по умолчанию 4096): Макс. токенов в ответе.
  - `temperature` (float, по умолчанию 0.7): Креативность генерации.
  - `timeout` (int, по умолчанию 60): Таймаут запроса (сек).
  - `history_limit` (int, по умолчанию 3): Глубина истории диалога.
  - `system_message` (str, опционально): Системный промпт.
  - `top_p`, `top_k` (опционально): Параметры семплирования.

**Инициализация:**
- Создает директории для логирования: `success`, `failed`, `prompts`.
- Проверяет валидность конфига (`_validate_config`).

---

#### **Публичные методы**

##### **1. `clear_conversation_history()`**
Очищает историю диалога. Вызывается при переполнении контекста или ошибках.

##### **2. `add_to_history(user_message: str, bot_message: str)`**
Добавляет сообщение пользователя/ассистента в историю.  
**Автосокращение:** Сохраняет только `history_limit * 2` последних сообщений.

##### **3. `generate_content(prompt_template: str, topic: str, context: str, max_tokens: Optional[int] = None) -> str`**
Генерирует контент через LLM API.  
**Параметры:**
- `prompt_template`: Шаблон промпта с плейсхолдерами `{TOPIC}`, `{CONTEXT}`.
- `topic`: Тема поста (подставляется в `{TOPIC}`).
- `context`: Контекст RAG (подставляется в `{CONTEXT}`).
- `max_tokens`: Переопределение `max_tokens` на время вызова.

**Логика:**
1. Строит сообщения с учетом лимитов (`_build_messages`).
2. Отправляет запрос к API (`_make_request`).
3. Валидирует и очищает ответ (`ContentValidator`).
4. При превышении `TELEGRAM_LIMIT` (4096 символов) запускает до 3 попыток сокращения.
5. Логирует результат в соответствующие директории.

**Возвращает:** Очищенный текст или пустую строку при ошибке.

##### **4. `generate_with_retry(prompt_template: str, topic: str, context: str, max_retries: int = 3) -> str`**
Повторяет генерацию при сбоях.  
**Стратегия повторов:**
- При HTTP-ошибках 413/400 сокращает `context` на 50%.
- После 3 ошибок очищает историю диалога.
- Финальная попытка: использует первые 256 символов контекста.

---

#### **Приватные методы**

##### **`_validate_config()`**
Проверяет валидность параметров конфига. Выбрасывает `AssertionError` при ошибках.

##### **`_clean_history() -> List[Dict[str, str]]`**
Фильтрует историю диалога:
- Удаляет пустые сообщения.
- Отбрасывает сообщения с `"nan"`.
- Сохраняет только роли `user`, `assistant`, `system`.

##### **`_truncate_context_for_llm(prompt_template: str, topic: str, context: str) -> str`**
Рассчитывает доступный размер контекста после подстановки `topic` и статических частей промпта. Возвращает усеченный `context`.

##### **`_build_messages(...) -> List[Dict[str, str]]`**
Формирует список сообщений для API:
1. Добавляет системное сообщение (если задано).
2. Добавляет историю диалога.
3. Вставляет финальный промпт с подставленными `{TOPIC}`, `{CONTEXT}`.
4. Сокращает общий размер до `LM_MAX_TOTAL_CHARS`.

##### **`_make_request(messages: List[Dict[str, str]]) -> str`**
Отправляет запрос к LLM API. Обрабатывает:
- Таймауты/сетевые ошибки.
- HTTP-ошибки (логирует статус и текст).
- Невалидный JSON в ответе.

**Возвращает:** Текст ответа или пустую строку при ошибке.

##### **`_save_lm_log(text: str, topic: str, success: bool, prompt: Optional[str] = None, attempt: int = 0)`**
Сохраняет лог в формате:  
`ГГГГММДД_ЧЧММСС_attempt{N}_{ТОПИК}.txt`  
Директории: `success`, `failed`, `prompts`.

---

#### **Логирование**
- **Уровень:** `DEBUG` (детали запросов), `WARNING` (сокращение контекста), `ERROR` (сбои API).
- **Директории:**
  - `logs/freegpt4/success` — валидные ответы.
  - `logs/freegpt4/failed` — пустые/невалидные ответы.
  - `logs/freegpt4/prompts` — промпты, отправленные в API.

---

#### **Пример использования**
```python
from modules.utils.config_manager import ConfigManager
from modules.content_generation.lm_client import FreeGPT4Client

# Загрузка конфига
config = ConfigManager.get_config()

# Инициализация клиента
lm_client = FreeGPT4Client(
    url="http://localhost:1337/v1/chat/completions",
    model="gpt-4",
    config=config["lm_client"]
)

# Генерация поста
prompt_template = "Напиши пост о {TOPIC} используя контекст: {CONTEXT}"
topic = "ИИ в медицине"
context = "ИИ помогает диагностировать рак..."  # Результат из RAG

post = lm_client.generate_with_retry(
    prompt_template=prompt_template,
    topic=topic,
    context=context
)

if post:
    print("Сгенерирован пост:", post[:50] + "...")
else:
    print("Ошибка генерации!")
```

---

#### **Зависимости**
- `content_validator.py`: Валидация и очистка контента.
- `config.json`: Параметры `temperature`, `max_tokens`, `history_limit`.
- Docker-контейнер: [Free-GPT4-WEB-API](https://github.com/Simatwa/Free-GPT4-WEB-API).